{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "# Paths\n",
        "data_path = Path(\"data/data_ver2/\")  # We can change the path later\n",
        "output_root = Path(\"data/data_ver2/split_data\")\n",
        "train_dir = output_root / \"train\"\n",
        "val_dir = output_root / \"val\"\n",
        "\n",
        "# Create output dirs\n",
        "for split_dir in [train_dir, val_dir]:\n",
        "    split_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Aggressive augmentation function\n",
        "def augment_image(img):\n",
        "    if random.random() > 0.5:\n",
        "        img = TF.hflip(img)\n",
        "    if random.random() > 0.5:\n",
        "        img = TF.vflip(img)\n",
        "    img = TF.rotate(img, random.uniform(-25, 25))\n",
        "    img = TF.adjust_brightness(img, random.uniform(0.7, 1.3))\n",
        "    img = TF.adjust_contrast(img, random.uniform(0.7, 1.3))\n",
        "    return img\n",
        "\n",
        "# Collect image paths and labels\n",
        "all_image_paths = []\n",
        "all_labels = []\n",
        "\n",
        "# Replace source_root with data_path\n",
        "for class_name in sorted(os.listdir(data_path)):\n",
        "    class_folder = data_path / class_name\n",
        "    if not class_folder.is_dir():\n",
        "        continue\n",
        "    for img_path in class_folder.glob(\"*\"):\n",
        "        if img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "            all_image_paths.append(img_path)\n",
        "            all_labels.append(class_name)\n",
        "\n",
        "# Stratified split into train/val\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    all_image_paths, all_labels, test_size=0.2, stratify=all_labels, random_state=42\n",
        ")\n",
        "\n",
        "# Copy files to split folders\n",
        "def copy_to_split(paths, labels, split_dir):\n",
        "    for img_path, label in zip(paths, labels):\n",
        "        target_dir = split_dir / label\n",
        "        target_dir.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy(img_path, target_dir / img_path.name)\n",
        "\n",
        "copy_to_split(train_paths, train_labels, train_dir)\n",
        "copy_to_split(val_paths, val_labels, val_dir)\n",
        "\n",
        "# Oversample minority classes in train/ using augmentation (especially folder 3 because it has only 2 tick images)\n",
        "# Count current class distribution\n",
        "from collections import Counter\n",
        "train_counts = Counter(train_labels)\n",
        "max_count = max(train_counts.values())\n",
        "\n",
        "print(\"Initial train class counts:\", train_counts)\n",
        "\n",
        "for class_name in train_counts:\n",
        "    class_folder = train_dir / class_name\n",
        "    images = list(class_folder.glob(\"*\"))\n",
        "    num_to_generate = max_count - train_counts[class_name]\n",
        "\n",
        "    for i in range(num_to_generate):\n",
        "        base_img_path = random.choice(images)\n",
        "        base_img = Image.open(base_img_path).convert(\"RGB\")\n",
        "        aug_img = augment_image(base_img)\n",
        "        aug_img.save(class_folder / f\"aug_{i}_{base_img_path.name}\")\n",
        "\n",
        "# Summary\n",
        "print(f\"\\n Data prepared.\")\n",
        "print(f\"Train data saved to: {train_dir}\")\n",
        "print(f\"Validation data saved to: {val_dir}\")\n",
        "\n",
        "# Check new distribution\n",
        "new_counts = {cls: len(list((train_dir / cls).glob(\"*\"))) for cls in os.listdir(train_dir)}\n",
        "print(\"Balanced train class counts:\", new_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCKzGKR_FSqW",
        "outputId": "78a6f613-5a8e-4068-9859-5f9ee5a5ac80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial train class counts: Counter({'2': 77, '1': 41, '4': 25, '3': 2})\n",
            "\n",
            " Data prepared.\n",
            "Train data saved to: data/data_ver2/split_data/train\n",
            "Validation data saved to: data/data_ver2/split_data/val\n",
            "Balanced train class counts: {'3': 226, '4': 178, '1': 149, '2': 77}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\"data/data_ver2/split_data/train\", transform=train_transform)\n",
        "val_dataset = datasets.ImageFolder(\"data/data_ver2/split_data/val\", transform=val_transform)"
      ],
      "metadata": {
        "id": "osZxzav_Fxo0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}